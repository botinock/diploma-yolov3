{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import cv2\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.10.19-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.13-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.7.2)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.1-py3-none-any.whl (22 kB)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-0.20.3-py2.py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 4.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.24.0)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.1)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.15.0)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.14.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.3.1)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.5-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "Building wheels for collected packages: promise, subprocess32, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=0ef54d0fcb11f003a473716046be1e6219937ef85405747cfa1e2539a5182e89\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6487 sha256=745c54a92f1d3d87ab4ae70a3d3a32c63649ffd2d87f19adc70cd78969034615\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8785 sha256=027fe2ead6e818c47d23489c59eb70a15c90cf66332f30d9de8886df1d3f4bd1\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise subprocess32 pathtools\n",
      "Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.13 configparser-5.0.1 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 promise-2.3 sentry-sdk-0.20.3 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.19\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r PKLot/images PKLot/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\tdetect.py\t    obj.data\t      test.py\t tutorial.ipynb\n",
      "PKLot\t\tdocker-compose.yml  obj.names\t      test.txt\t utils\n",
      "Untitled.ipynb\thubconf.py\t    park.yaml\t      train.py\t valid.txt\n",
      "data\t\tmodels\t\t    requirements.txt  train.txt  weights\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print('123')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25773\n",
      "done\n",
      "--- 122.69055151939392 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "train = open('train.txt', 'w')\n",
    "valid = open('valid.txt', 'w')\n",
    "test = open('test.txt', 'w')\n",
    "error = 0\n",
    "ind = 0\n",
    "try:\n",
    "    os.mkdir('PKLot/images')\n",
    "    os.mkdir('PKLot/images/train')\n",
    "    os.mkdir('PKLot/images/val')\n",
    "    os.mkdir('PKLot/images/test')\n",
    "    os.mkdir('PKLot/labels')\n",
    "    os.mkdir('PKLot/labels/train')\n",
    "    os.mkdir('PKLot/labels/val')\n",
    "    os.mkdir('PKLot/labels/test')\n",
    "except:\n",
    "    pass\n",
    "for folder in os.walk('PKLot/PKLot/PKLot/'):\n",
    "    for file_name in folder[2]:\n",
    "        if \"xml\" in file_name:\n",
    "            if ind%10 < 7:\n",
    "                f = open('PKLot/labels/train/' + file_name[:-3] + 'txt', 'w')\n",
    "#                 try:\n",
    "#                     shutil.move(folder[0] + '/' + file_name[:-3] + 'jpg', 'PKLot/images/train/' + file_name[:-3] + 'jpg')\n",
    "#                 except Exception as e:\n",
    "#                     pass\n",
    "                shutil.copy(folder[0] + '/' + file_name[:-3] + 'jpg', 'PKLot/images/train/' + file_name[:-3] + 'jpg')\n",
    "                if 'PUCPR' in folder[0]:\n",
    "                    pts = np.array([[300,190], [1280, 190], [1280, 500], [700, 500], [700, 600], [0, 600]])\n",
    "                    img = cv2.imread('PKLot/images/train/' + file_name[:-3] + 'jpg')\n",
    "                    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "                    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "                    dst = cv2.bitwise_and(img, img, mask=mask)\n",
    "                    cv2.imwrite('PKLot/images/train/' + file_name[:-3] + 'jpg', dst)\n",
    "                train.write('PKLot/images/train/' + file_name[:-3] + 'jpg\\n')\n",
    "            elif ind%10 < 9:\n",
    "                f = open('PKLot/labels/val/' + file_name[:-3] + 'txt', 'w')\n",
    "                try:\n",
    "                    shutil.copy(folder[0] + '/' + file_name[:-3] + 'jpg', 'PKLot/images/val/' + file_name[:-3] + 'jpg')\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                if 'PUCPR' in folder[0]:\n",
    "                    pts = np.array([[300,190], [1280, 190], [1280, 500], [700, 500], [700, 600], [0, 600]])\n",
    "                    img = cv2.imread('PKLot/images/val/' + file_name[:-3] + 'jpg')\n",
    "                    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "                    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "                    dst = cv2.bitwise_and(img, img, mask=mask)\n",
    "                    cv2.imwrite('PKLot/images/val/' + file_name[:-3] + 'jpg', dst)\n",
    "                valid.write('PKLot/images/val/' + file_name[:-3] + 'jpg\\n')\n",
    "            else:\n",
    "                f = open('PKLot/labels/test/' + file_name[:-3] + 'txt', 'w')\n",
    "                try:\n",
    "                    shutil.copy(folder[0] + '/' + file_name[:-3] + 'jpg', 'PKLot/images/test/' + file_name[:-3] + 'jpg')\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "                test.write('PKLot/images/test/' + file_name[:-3] + 'jpg\\n')\n",
    "            ind = ind + 1\n",
    "            tree = ET.parse(folder[0] + '/' + file_name)\n",
    "            root = tree.getroot()\n",
    "            for i in root:\n",
    "                try:\n",
    "                    tx = []\n",
    "                    ty = []\n",
    "                    for a in range(4):\n",
    "                        tx.append(int(i[1][a].attrib['x']))\n",
    "                        ty.append(int(i[1][a].attrib['y']))\n",
    "                    x = (max(tx) + min(tx))/2\n",
    "                    y = (max(ty) + min(ty))/2\n",
    "                    width = max(tx) - min(tx)\n",
    "                    height = max(ty) - min(ty)\n",
    "                    f.write(\"{} {} {} {} {}\\n\".format(i.attrib['occupied'],\n",
    "                                                int(x)/1280.,\n",
    "                                                int(y)/720.,\n",
    "                                                int(width)/1280.,\n",
    "                                                int(height)/720.\n",
    "                                                ))\n",
    "                    \"\"\"\n",
    "                    f.write(\"{} {} {} {} {} {}\\n\".format(i.attrib['occupied'],\n",
    "                                                float(i[0][0].attrib['x'])/1280,\n",
    "                                                float(i[0][0].attrib['y'])/720,\n",
    "                                                float(i[0][1].attrib['w'])/1280,\n",
    "                                                float(i[0][1].attrib['h'])/720,\n",
    "                                                np.sin(-float(i[0][2].attrib['d']) * np.pi / 180.)))\"\"\"\n",
    "                    \"\"\"if float(i[0][2].attrib['d']) > max_a:\n",
    "                        max_a = float(i[0][2].attrib['d'])\n",
    "                    if float(i[0][2].attrib['d']) < min_a:\n",
    "                        min_a = float(i[0][2].attrib['d'])\"\"\"\n",
    "                except:\n",
    "                    error = error + 1\n",
    "            f.close()\n",
    "print(error)\n",
    "print('done')\n",
    "train.close()\n",
    "valid.close()\n",
    "test.close()\n",
    "#print(max_a)\n",
    "#print(min_a)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/botinock/diploma-yolov3.git ✅\n",
      "YOLOv3 aef851e torch 1.8.0a0+1606899 CUDA:0 (GeForce GTX 1660 Ti with Max-Q Design, 6144.0MB)\n",
      "\n",
      "Namespace(adam=True, batch_size=16, bucket='', cache_images=False, cfg='./models/yolov3.yaml', data='park.yaml', device='', epochs=3, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp15', single_cls=False, sync_bn=False, total_batch_size=16, weights='runs/train/exp4/weights/last.pt', workers=16, world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
      "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
      " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
      " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
      " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
      " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
      " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
      " 28      [27, 22, 15]  1     37695  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model Summary: 333 layers, 61529119 parameters, 61529119 gradients, 155.1 GFLOPS\n",
      "\n",
      "Transferred 438/440 items from runs/train/exp4/weights/last.pt\n",
      "Scaled weight_decay = 0.0005\n",
      "Optimizer groups: 75 .bias, 75 conv.weight, 72 other\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbotinock\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.21 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.10.19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mexp15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/botinock/YOLOv3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/botinock/YOLOv3/runs/1onyvcdl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /usr/src/app/wandb/run-20210302_195226-1onyvcdl\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'PKLot/labels/train' for images and labels... 8693 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 8693/8693 [00:08<00:00, 984.08it/s] \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: PKLot/labels/train.cache\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'PKLot/labels/train.cache' for images and labels... 8693 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 8693/8693 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'PKLot/labels/val.cache' for images and labels... 2482 found, 0 missing, 0 empty, 0 corrupted: 100%|██████████| 2482/2482 [00:00<?, ?it/s]\n",
      "Plotting labels... \n",
      "Images sizes do not match. This will causes images to be display incorrectly in the UI.\n",
      "\n",
      "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.50, Best Possible Recall (BPR) = 1.0000\n",
      "Image sizes 416 train, 416 test\n",
      "Using 16 dataloader workers\n",
      "Logging results to runs/train/exp15\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
      "       0/2     4.92G   0.03577   0.07483  0.001631    0.1122      1831       416:  14%|█▍        | 75/544 [01:12<06:53,  1.13it/s] ^C\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 416 --batch-size 16 --epochs 3 --data park.yaml --cfg yolov3.yaml --adam --weights runs/train/exp4/weights/last.pt --workers 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(augment=False, batch_size=32, conf_thres=0.001, data='park.yaml', device='', exist_ok=False, img_size=640, iou_thres=0.6, name='exp', project='runs/test', save_conf=False, save_hybrid=False, save_json=False, save_txt=False, single_cls=False, task='val', verbose=True, weights=['runs/train/exp12/weights/best.pt'])\n",
      "YOLOv3 aef851e torch 1.8.0a0+1606899 CUDA:0 (GeForce GTX 1660 Ti with Max-Q Design, 6144.0MB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 261 layers, 61502815 parameters, 0 gradients, 154.9 GFLOPS\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'PKLot/labels/val' for images and labels... 2482 found, 0 missing,\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: PKLot/labels/val.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning 'PKLot/labels/val.cache' for images and labels... 2482 found, 0 mi\u001b[0m\n",
      "               Class      Images     Targets           P           R      mAP@.5\n",
      "                 all    2.48e+03           0           0           0           0           0\n",
      "Speed: 102.2/1.5/103.7 ms inference/NMS/total per 640x640 image at batch-size 32\n",
      "Results saved to runs/test/exp6\n"
     ]
    }
   ],
   "source": [
    "!python test.py --data park.yaml --weights runs/train/exp12/weights/best.pt --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --data park.yaml --weights runs/train/exp12/weights/best.pt --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.general as general\n",
    "import torch\n",
    "import numpy as np\n",
    "#import utils.rotated as rotated \n",
    "from utils.rotated.oriented_iou_loss import cal_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "box_1 = torch.tensor([[1, 1, 2, 3], [1, 1, 4, 5]]).view([2, 4])\n",
    "box_2 = torch.tensor([[1, 1, 6, 7], [1, 1, 8, 9]]).view([2, 4])\n",
    "print(box_1.shape, box_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cdee628378e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# load the Tetris block image, convert it to grayscale, and threshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[3:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 934 ms, sys: 74 µs, total: 934 ms\n",
      "Wall time: 930 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000000):\n",
    "#     b = 0\n",
    "    b = [a[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.50000, 0.50000],\n",
       "        [0.50000, 0.50000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general.box_iou(box_1, box_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 25]) torch.Size([3, 3, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]], device='cuda:0'),\n",
       " tensor([[[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]],\n",
       " \n",
       " \n",
       "         [[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]],\n",
       " \n",
       " \n",
       "         [[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]]], device='cuda:0'),\n",
       " tensor([[[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]],\n",
       " \n",
       " \n",
       "         [[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]],\n",
       " \n",
       " \n",
       "         [[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]]], device='cuda:0'),\n",
       " tensor([[4., 4., 4.],\n",
       "         [4., 4., 4.],\n",
       "         [4., 4., 4.]], device='cuda:0'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box1 = torch.tensor([[1, 1, 2, 2, 0], [1, 1, 2, 2, 0], [1, 1, 2, 2, 0]], device=\"cuda:0\").view([3, 1, 5]).repeat([1, 3, 5])\n",
    "box2 = torch.tensor([[1, 1, 2, 2, 0], [1, 1, 2, 2, 0], [1, 1, 2, 2, 0]], device=\"cuda:0\").view([1, 3, 5]).repeat([3, 1, 5])\n",
    "print(box1.shape, box2.shape)\n",
    "cal_iou(box1, box2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.00000, 0.70711]], device='cuda:0'),\n",
       " tensor([[[[ 2.00000,  2.00000],\n",
       "           [ 0.00000,  2.00000],\n",
       "           [ 0.00000,  0.00000],\n",
       "           [ 2.00000,  0.00000]],\n",
       " \n",
       "          [[ 1.00056,  2.41421],\n",
       "           [-0.41421,  1.00056],\n",
       "           [ 0.99944, -0.41421],\n",
       "           [ 2.41421,  0.99944]]]], device='cuda:0'),\n",
       " tensor([[[[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]],\n",
       " \n",
       "          [[2., 2.],\n",
       "           [0., 2.],\n",
       "           [0., 0.],\n",
       "           [2., 0.]]]], device='cuda:0'),\n",
       " tensor([[4.00000, 4.68629]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv3 aef851e torch 1.8.0a0+1606899 CUDA:0 (GeForce GTX 1660 Ti with Max-Q Design, 6144.0MB)\n",
      "\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     20672  models.common.Bottleneck                [64, 64]                      \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    164608  models.common.Bottleneck                [128, 128]                    \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  8   2627584  models.common.Bottleneck                [256, 256]                    \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  8  10498048  models.common.Bottleneck                [512, 512]                    \n",
      "  9                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      " 10                -1  4  20983808  models.common.Bottleneck                [1024, 1024]                  \n",
      " 11                -1  1   5245952  models.common.Bottleneck                [1024, 1024, False]           \n",
      " 12                -1  1    525312  models.common.Conv                      [1024, 512, [1, 1]]           \n",
      " 13                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 14                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
      " 15                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 1]             \n",
      " 16                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 18           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
      " 19                -1  1   1377792  models.common.Bottleneck                [768, 512, False]             \n",
      " 20                -1  1   1312256  models.common.Bottleneck                [512, 512, False]             \n",
      " 21                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 22                -1  1   1180672  models.common.Conv                      [256, 512, 3, 1]              \n",
      " 23                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 24                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 25           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 26                -1  1    344832  models.common.Bottleneck                [384, 256, False]             \n",
      " 27                -1  2    656896  models.common.Bottleneck                [256, 256, False]             \n",
      " 28      [27, 22, 15]  1     43080  Detect                                  [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
      "Model Summary: 333 layers, 61534504 parameters, 61534504 gradients, 155.1 GFLOPS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python models/yolo_rotate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\tdocker-compose.yml  runs\t\t    tutorial.ipynb\n",
      "PKLot\t\thubconf.py\t    sort_vertices.egg-info  utils\n",
      "Untitled.ipynb\tmodels\t\t    test.py\t\t    valid.txt\n",
      "__pycache__\tobj.data\t    test.txt\t\t    wandb\n",
      "build\t\tobj.names\t    train.py\t\t    weights\n",
      "data\t\tpark.yaml\t    train.txt\t\t    yolov3.pt\n",
      "detect.py\trequirements.txt    train_rotate.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"utils/rotated/demo.py\", line 25, in <module>\n",
      "    from oriented_iou_loss import cal_diou, cal_giou\n",
      "  File \"/usr/src/app/utils/rotated/oriented_iou_loss.py\", line 3, in <module>\n",
      "    from utils.rotated.box_intersection_2d import oriented_box_intersection_2d\n",
      "ModuleNotFoundError: No module named 'utils'\n"
     ]
    }
   ],
   "source": [
    "!python utils/rotated/demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r utils/build"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
